<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Handong Zhao</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro" />
		  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
		  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
		  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
 		<link rel="stylesheet" href="assets/css/main.css" />
<!-- 		<link rel="stylesheet" href="font-awesome.min.css" /> -->
		<!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css"> -->
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
	</head>
	<body id="top">
		<!-- Header -->
			<header id="header">
				<a href="#" class="image avatar"><img src="images/handong_2022apr.jpg" alt="" /></a>
				<!-- <h1><strong> Handong Zhao</strong></h1> -->
				<!-- <ul class="icons">
					 <li><a href="mailto:hazhao@adobe.com" class="icon fa-envelope-o"><span class="label">Email</span></a></li>
					<li><a href="https://www.linkedin.com/in/handong-zhao-b6828b2b/" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
					<li><a href="https://scholar.google.com/citations?user=0f-YOFgAAAAJ&hl=en&oi=ao" class="icon fa-google"><span class="label">GoogleScholar</span></a></li>
					<li><a href="https://github.com/hdzhao/" class="icon fa-github"><span class="label">Instagram</span></a></li> -->
					
					
				</ul>

			</header>

		<!-- Main -->
			<div id="main">

				<!-- One -->
					<section id="one">
						<header class="major">
							<h2>About Me<br />
							</h2>
						</header>
						<p> My name is Handong Zhao. I am a senior research scientist at <a href="https://research.adobe.com/" target="_blank">Adobe Research</a>, San Jose, CA. I obtained the Ph.D. degree at <a href="http://www.ece.neu.edu/" target="_blank">Department of Electrical & Computer Engineering</a>, <a href="http://www.northeastern.edu/" target="_blank">Northeastern University</a>, Boston, MA. My current research interest includes vision language modeling at scale, and its applications on analysis and generation tasks. I was the recipient of the <a href="https://www.nsf.gov/news/special_reports/i-corps/index.jsp" target="_blank">National Science Foundation’s Innovation Corps (I-Corps™) program</a> award as an entrepreneurial lead. Me at </font> [<a href="https://scholar.google.com/citations?user=0f-YOFgAAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a>]</font> [<a href="http://dblp.uni-trier.de/pers/hd/z/Zhao:Handong" target="_blank">DBLP</a>] </font> [<a href="https://research.adobe.com/person/handong-zhao/" target="_blank">Adobe Profile</a>]</font></p>

						
<ul type="circle" >
						

						<!-- <p> <font color="#ff0000" style="font-weight:bolder">I am looking for a research intern working on deep learning and transfer learning. </font>If you're interested, feel free to drop me an email along with your CV.</p> -->

						<!-- <div class="4u$ 12u$(small)"> -->
								<ul class="labeled-icons">
									<!-- <li > -->
										<i class="icon fa-envelope-o"><span class="label"> Email </span></i>
										&ensp;hazhao [at] adobe.com 
										<div style="line-height:60%;">
										    <br>
										</div>
									<!-- </li> -->
									<!-- <li> -->
										<i class="icon fa-home"><span class="label">Address</span></i>
										&ensp;321 Park Avenue, San Jose, CA, 95112
									<!-- </li> -->
								</ul>

							<!-- </div> -->

 </ul>
 <p>
 <font color="#ff0000">[Internship]</font>
 I am hiring self-motivated Ph.D. student research interns (on a rolling basis) for the summer of 2025.
 My current research interests include (but are not limited to) multimodal LLM for visual analysis and generation.
 Please contact me if you are interested in working with me, including your CV and a short description of what you want to do during the internship.
 </p>			
					
				</ul>

					</section>

<section id="Two">
<h2> Recent News </h2>
<li>[10/24] Appointed as ICLR-24 Area Chair.</i>.</li>
<li>[09/24] One NeurIPS-24 and two EMNLP-24 papers accepted on <i>VL representation learning and Multimodal LLM</i>.</li>
<li>[07/24] One ECCV-2024 accepted on <i>Training-free Domain Generalization</i>.</li>
<li>[05/24] One TMLR journal accepted on <i>Continual Graph Learning</i>.</li>
<li>[01/24] One ICLR-2024 accepted on <i>Self-supervised Learning for Entity Segmentation</i>.</li>
<li>
<!-- <div class="panel-group" > -->
  <!-- <div class="panel panel-default" style="border: 0 !important;"> -->
    <div class="panel-heading" style="background-image:none; background: #ffffff; padding: 0px;">
      <h4 class="panel-title">
        <a data-toggle="collapse" href="#collapse1">More ...</a>
      </h4>
    </div>
    <div id="collapse1" class="panel-collapse collapse">
      <ul type="circle">
	<li>[09/23] One NeurIPS-2023 paper accepted on <i><a href="https://arxiv.org/abs/2306.04933" target="_blank">InfoPrompt for NLU</a></i>.</li>
	<li>[07/23] One ICCV-2023 paper accepted on <i><a href="https://arxiv.org/abs/2304.03869" target="_blank">Spatial-Temporal Attention Controlled Diffusion Model</a></i>.</li>
	<li>[05/23] One <a href="https://2023.aclweb.org/" target="_blank">ACL-2023</a> finding paper accepted on "<i>Domain Adaptation for Named Entity Recognition</i>".</li>
	<li>[03/23] One <a href="https://cvpr2023.thecvf.com/" target="_blank">CVPR-2023</a> paper accepted on "<i>Uncovering Disentaglement Capability of Diffusion Models</i>".</li>
	<li>[01/23] Appointed as Associate Editor for for IEEE TCSVT.</li>
	<li>[01/23] One <a href="https://iclr.cc/" target="_blank">ICLR-2023</a> paper accepted on "<i>Continual Federated Learning</i>".</li>
	<li>[11/22] One <a href="https://aaai.org/Conferences/AAAI-23/" target="_blank">AAAI-2023</a> paper accepted on "<i>Compositional Image Retrieval</i>".</li>
	<li>[10/22] Two <a href="https://2022.emnlp.org/" target="_blank">EMNLP-2022</a> papers accepted on "<i>Multilingual Rep. Learning</i>".</li>
	<li>[08/22] Four <a href="https://www.cikm2022.org/" target="_blank">CIKM-2022</a> papers accepted.</li>
	<li>[06/22] One <a href="https://recsys.acm.org/recsys22/" target="_blank">RecSys-2022</a> on "<i>Conversational Bundle Rec</i>" accepted as oral.</li>
	<li>[06/22] Gave a talk on <i>Federated Knowledge Composition</i> in CVPR FedVision Workshop. <a href="https://sites.google.com/view/fedvision" target="_blank">[video recording]</a></li>
	<li>[05/22] One <a href="https://kdd.org/kdd2022/index.html" target="_blank">KDD-2022</a> on "<i>KG Infusion for Tabular Pre-training Models</i>" accepted.</li>
	<li>[04/22] One <a href="https://sigir.org/sigir2022/" target="_blank">SIGIR-2022</a> on "<i>Cross-domain Interaction Recommendation</i>" accepted.</li>
	<li>[03/22] One <a href="https://cvpr2022.thecvf.com/" target="_blank">CVPR-2022</a> on "<i>Fashion CLIP</i>" and one <a href="https://l4dc.stanford.edu/" target="_blank">L4DC-2022</a> on "<i>Neural Spatiotemporal Point Process</i>" accepted.</li>
	<li>[02/22] Two <a href="https://www.2022.aclweb.org/" target="_blank">ACL-2022</a> papers accepted on "<i>Few-Shot Class-Incremental NER</i>" and "<i>Learning Adaptive Axis Attentions in Fine-tuning (Finding paper)</i>".</li>
	<li>[01/22] One paper "<i>Neural Contextual Bandits with Deep Representation and Shallow Exploration</i>" accepted by <a href="https://iclr.cc/" target="_blank">ICLR-2022</a>.</li>
	<li>[01/22] One paper on "<i>Federated Learning for Multilingual NLU</i>" accepted by <a href="https://www2022.thewebconf.org/" target="_blank">WWW-2022</a>.</li>
	<li>[12/21] One paper on "<i>Continual Federated Learning</i>" accepted by <a href="https://iclr.cc//" target="_blank">ICLR-2023</a>.</li>
	<li>[12/21] One paper on "<i>Cross-Domain Clustering</i>" accepted by <a href="https://aaai.org/Conferences/AAAI-22/" target="_blank">AAAI-2022</a> student abstract and poster program.</li>
	<li>[10/21] Two papers on "<i>Continual NER</i>" and "<i>User-in-the-loop NER</i>" accepted by <a href="https://neurips2021-nlp.github.io/" target="_blank">NeurIPS ENLSP Workshop</a>.</li>
	<li>[09/21] Two papers on "<i>KD-based Graph Similarity Computation </i>" and "<i>Document Representation Learning</i>" accepted by <a href="https://nips.cc/" target="_blank">NeurIPS-2021</a>.</li>
	<li>[08/21] One short paper on "<i>Sequential Recommender System</i>" accepted by <a href="https://www.cikm2021.org/" target="_blank">CIKM-2021</a>.</li>
	<li>[07/21] Two papers on "<i>Source-Free DA</i>" and "<i>Semi-Supervised DA</i>" accepted by <a href="http://iccv2021.thecvf.com/home" target="_blank">ICCV-2021</a>.</li>
	<li>[05/21] One paper on "<i>Explainable Column Annotation</i>" accepted by <a href="https://kdd.org/kdd2021/" target="_blank">KDD-2021</a>.</li>
	<li>[05/21] One paper on "<i>KG-based Commonsense Reasoning</i>" accepted by Findings of <a href="https://2021.aclweb.org/" target="_blank">ACL-2021</a>.</li>
	<li>[04/21] I'm co-organizing <a href="https://cmliot2021.github.io/" target="_blank">The 3rd Workshop on Continual and Multimodal Learning for Internet of Things (CML-IOT)</a>, at IJCAI-2021. The qualified papers are planned to invited as submissions to a journal special issue. </li>
	<li>[03/21] One <a href="http://cvpr2021.thecvf.com/" target="_blank">CVPR-2021</a> on "<i>Document Representation Learning</i>" and one <a href="https://2021.naacl.org/" target="_blank">NAACL-2021</a> on "<i>KG Enrichment</i>" got accepted.</li>
	<li>[01/21] One <a href="https://iclr.cc/" target="_blank">ICLR-2021</a> on "<i>Learning to Deceive KG</i>" accepted.</li>	
	<li>[12/20] One <a href="https://kr2ml.github.io/2020/" target="_blank">NeurIPS-KR2ML</a> workshop paper on "<i>KG-based Commonsense Reasoning</i>" accepted.</li>
	<li>[11/20] One paper on "<i>Learnable Subspace Clustering</i>" accepted by TNNLS. <a href="https://arxiv.org/abs/2004.04520" target="_blank">[arXiv]</a>.</li>
	<li>[09/20] One <a href="https://nips.cc/" target="_blank">NeurIPS-2020</a> on "<i>Self-Supervised Relationship Probing</i>" accepted.</li>
	<!-- <li>[02/20] Accepted the invitations to serve as PC for <a href="https://ijcai20.org/" target="_blank">IJCAI-2020</a> and <a href="https://2020.acmmm.org/" target="_blank">ACMMM-2020</a>.</a></li> -->	
	<li>[07/20] One <a href="https://eccv2020.eu/" target="_blank">ECCV-2020</a> on "<i>Open Domain Image Manipulation</i>" and one <a href="https://www.cikm2020.org/" target="_blank">CIKM-2020</a> on "<i>KG Reasoning for Recommendation</i>" accepted.</li>
	<li>[06/20] One paper on "<i>Linear Quadratic Regulator</i>" accepted by <a href="https://icml.cc/" target="_blank">ICML-2020</a>.</li>
	<li>[05/20] One paper on "<i>Personalized Image Retrieval</i>" accepted by <a href="https://www.kdd.org/kdd2020/" target="_blank">KDD-2020</a>.</li>
	<li>[04/20] One survey paper on "<i>Representation Learning for User Modeling</i>" was accepted by <a href="https://www.ijcai20.org/" target="_blank">IJCAI-2020</a>.</li>
	<li>[03/20] Our <a href="https://www.ijcai20.org/" target="_blank">IJCAI-2020</a> tutorial "<i>Robust Multi-view Visual Learning: A Knowledge Flow Perspective</i>" was accepted (with prof. Zhengming Ding and prof. Ming Shao).</li>
	<li>[02/20] One paper on "<i>Cross-domain Document Object Detection</i>" was accepted by <a href="http://cvpr2020.thecvf.com/" target="_blank">CVPR-2020</a>.</li>
	      <li>[11/19] One <a href="https://acmsocc.github.io/2019/" target="_blank">SoCC-2019</a> poster and one <a href="http://bigdataieee.org/BigData2019/" target="_blank">BigData-2019</a> paper accepted.</li>
	<li>[09/19] I gave a talk on "<i>Multi-modal Representation Learning</i>", invited by Prof. Hongfu Liu at Brandeis.</li>
		<li>[07/19] One <a href="http://iccv2019.thecvf.com/" target="_blank">ICCV-2019</a> paper got accepted. Congratulations to Jiuxiang.</li>
	      <li>[04/19] Two <a href="https://www.kdd.org/kdd2019/" target="_blank">KDD-2019</a> papers accepted on the topics of "<i>Sequential Adversarial Learning</i>" and "<i>Interpretable User Modeling</i>".</li>	
		<!-- <li>[03/19] Accepted the invitation to serve as PC member for <a href="https://www.acmmm.org/2019/" target="_blank">ACM MM-2019</a>.</li> -->
		<li>[02/19] My FIRST summer intern Jiuxiang's work on "<i>Scene Graph Generation</i>" got accepted by <a href="http://cvpr2019.thecvf.com/" target="_blank">CVPR-2019</a>.</li>
		<li>[02/19] Co-host (with Myra and Subrata) session "<i>AI For System</i>" won Top Ten Session in Adobe-TechSummit-2019. Got my first trophy at Adobe.
		<li>[12/18] Accepted the invitation to serve as PC member for <a href="https://ijcai19.org/" target="_blank">IJCAI-2019</a>.</li>
		<li>[11/18] Will host a mini-summit, "<i>Analyze, Predict, and Visualize: when RNNs meet Adobe</i>", at <a href="https://research.adobe.com/adobe-tech-summit/" target="_blank">Adobe-TechSummit-2019</a> with Sungchul Kim.</li>
		<li>[10/18] I have one paper accepted by <a href="http://www.wsdm-conference.org/2019/" target="_blank">WSDM-2019</a> (Acceptance Rate: 16.4%).</li>
		<li>[10/18] <a href="https://aaai.org/Conferences/AAAI-19/" target="_blank">AAAI-2019</a> Tutorial "<i>Deep Multi-view Data Analytics</i>" was accepted (with Allan Ding and Hongfu Liu).</li>
		<li>[05/18] Accepted the invitations to serve as PC for <a href="https://nips.cc/Conferences/2018/" target="_blank">NIPS-2018</a> and SPC for <a href="https://aaai.org/Conferences/AAAI-19/" target="_blank">AAAI-2019</a>.</a></li>
		<li>[03/18] One book proposal (with Allan and Prof. Raymond Fu) is accepted by Springer.</a></li>
		<li>[03/18] I accepted the invitation to serve as a member of the Program Committee for <a href="https://web.northeastern.edu/smilelab/AMFG2018/" target="_blank">CVPR-2018 workshop on Analysis and Modeling of Faces and Gestures (AMFG).</a></li>
		<li>[02/18] I accepted the invitation to serve as a member of the Program Committee for <a href="http://www.icmla-conference.org/icmla18/" target="_blank">ICMLA-2018.</a></li>
		<li>[01/18] I have one paper accepted by <a href="http://wacv18.uccs.us/" target="_blank">WACV-2018</a>.</li>
      </ul>
    </div>
  <!-- </div> -->
<!-- </div> -->
</li>
</ul>
</section>


<section id="Three">
    <h2> Some recent papers and talks </h2>

    <div class="paper-container">
        <div class="thumbnail">
            <a href="https://www.youtube.com/watch?v=q9cpxSseKFE&feature=youtu.be" target="_blank">
                <img src="https://img.youtube.com/vi/q9cpxSseKFE/0.jpg" alt="YouTube Recording Thumbnail" />
            </a>
        </div>
        <div class="paper-details">
            <p>
                Keynote: <a href="https://sites.google.com/view/fedvision?pli=1" target="_blank">Federated Knowledge Composition</a><br />
		Handong Zhao <br />
                FedVision: International Workshop on Federated Learning for Computer Vision<br />
                In conjunction with CVPR 2022, New Orleans, Louisiana. 
                [<a href="https://www.youtube.com/watch?v=q9cpxSseKFE&feature=youtu.be" target="_blank">Recording</a>]
            </p>
        </div>
    </div>

    <!-- First new paper entry -->
    <div class="paper-container">
        <div class="thumbnail">
            <img src="https://daiqing-qi.github.io/daiqing/assets/publications/fashion.png" alt="E2: Easy Contrastive Learning Thumbnail" />
        </div>
        <div class="paper-details">
            <p>
                E2: Easy Contrastive Learning of Expressive Fashion Representations<br />
                Daiqing Qi, Handong Zhao, Sheng Li<br />
                NeurIPS 2024
<!--                 <br /><button>Arxiv</button> -->
            </p>
        </div>
    </div>

    <!-- Second new paper entry -->
     <div class="paper-container">
        <div class="thumbnail">
            <img src="https://wuqiuche.github.io/images/diffusiondisentangle.png" alt="Harnessing Spatial-Temporal Attention Thumbnail" />
        </div>
        <div class="paper-details">
            <p>
                Uncovering the Disentanglement Capability in Text-to-Image Diffusion Models<br />
                Qiucheng Wu, Yujian Liu, Handong Zhao, Ajinkya Kale, Trung Bui, Tong Yu, Zhe Lin, Yang Zhang, Shiyu Chang<br />
                CVPR, 2023 [<a href="https://github.com/UCSB-NLP-Chang/DiffusionDisentanglement" target="_blank">Code</a>] [<a href="https://wuqiuche.github.io/DiffusionDisentanglement-project-page/" target="_blank">Demo</a>]
            </p>
        </div>
    </div>

</section>

<style>
    .paper-container {
        display: flex;
        align-items: center;
        margin-top: 20px;
    }

    .thumbnail {
        flex: 0 0 auto;
        margin-right: 20px;
    }

    .thumbnail img {
        width: 200px;
        height: auto;
        border-radius: 5px;
    }

    .paper-details {
        flex: 1;
    }

    .paper-details p {
        margin: 0;
    }

    button {
        margin-top: 10px;
        padding: 5px 10px;
        background-color: #f0f0f0;
        border: 1px solid #ddd;
        cursor: pointer;
    }

    button:hover {
        background-color: #e0e0e0;
    }
</style>




	
<!-- <li> 
Tutorial: Robust Multi-view Visual Learning: A Knowledge Flow Perspective <br />
Jointly organized with Zhengming Ding and Ming Shao<br />
IJCAI-2020, virtual.
</li>
	
<li> 
Tutorial: Analyze, Predict and Visualize: When RNNs Meet Adobe <br />
Jointly organized with Sungchul Kim, Fan Du and Sana Malik<br />
Adobe Tech Summit 2019, San Francisco, CA, February 2019.
</li>
	
<li> 
Tutorial: <a href="https://aaai.org/Conferences/AAAI-19/aaai19tutorials/" target="_blank"> Deep Multi-View Visual Data Analytics</a> <br />
Jointly organized with Zhengming Ding and Hongfu Liu<br />
AAAI-2019, Honolulu, Hawaii, January 2019.
</li>
	
<li> 
Tutorial: <a href="http://www.fg2017.org/index.php/tutorials/" target="_blank"> Multi-view Face Representation</a> <br />
Jointly organized with Zhengming Ding and Yun Raymond Fu<br />
FG-2017, Washington, D.C., May 2017.
</li> -->
<!-- <li> 
Graduate Teaching Assistant: <a href="https://wl11gp.neu.edu/udcprod8/bwckctlg.p_display_courses" target="_blank"> Data Visualization (EECE 5642)</a> <br />
 Lecturer: Prof. Yun Raymond Fu.<br />
 Department of ECE, Northeastern University, Spring 2017.
</li>
<li> 
Graduate Teaching Assistant: <a href="https://wl11gp.neu.edu/udcprod8/bwckctlg.p_disp_course_detail?cat_term_in=201310&subj_code_in=EECE&crse_numb_in=7205" target="_blank"> Fundamental of Computer Engineering (EECE 7205)</a> <br />
Lecturer: Prof. Stefano Basagni. <br />
Department of ECE, Northeastern University, Fall 2016.
</li>
<li> 
Graduate Teaching Assistant: <a href="https://wl11gp.neu.edu/udcprod8/bwckctlg.p_disp_course_detail?cat_term_in=201310&subj_code_in=EECE&crse_numb_in=7205" target="_blank"> Fundamental of Computer Engineering (EECE 7205)</a> <br />
Lecturer: Prof. Stefano Basagni. <br />
Department of ECE, Northeastern University, Fall 2014.
</li> -->
</ol>
</section>

				
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
